{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f73b06ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting langgraph\n",
      "  Downloading langgraph-0.6.6-py3-none-any.whl.metadata (6.8 kB)\n",
      "Requirement already satisfied: langchain-core>=0.1 in d:\\study\\gen ai\\langchain\\.venv\\lib\\site-packages (from langgraph) (0.3.75)\n",
      "Collecting langgraph-checkpoint<3.0.0,>=2.1.0 (from langgraph)\n",
      "  Downloading langgraph_checkpoint-2.1.1-py3-none-any.whl.metadata (4.2 kB)\n",
      "Collecting langgraph-prebuilt<0.7.0,>=0.6.0 (from langgraph)\n",
      "  Downloading langgraph_prebuilt-0.6.4-py3-none-any.whl.metadata (4.5 kB)\n",
      "Collecting langgraph-sdk<0.3.0,>=0.2.2 (from langgraph)\n",
      "  Downloading langgraph_sdk-0.2.4-py3-none-any.whl.metadata (1.5 kB)\n",
      "Requirement already satisfied: pydantic>=2.7.4 in d:\\study\\gen ai\\langchain\\.venv\\lib\\site-packages (from langgraph) (2.11.7)\n",
      "Collecting xxhash>=3.5.0 (from langgraph)\n",
      "  Downloading xxhash-3.5.0-cp313-cp313-win_amd64.whl.metadata (13 kB)\n",
      "Collecting ormsgpack>=1.10.0 (from langgraph-checkpoint<3.0.0,>=2.1.0->langgraph)\n",
      "  Downloading ormsgpack-1.10.0-cp313-cp313-win_amd64.whl.metadata (44 kB)\n",
      "Requirement already satisfied: httpx>=0.25.2 in d:\\study\\gen ai\\langchain\\.venv\\lib\\site-packages (from langgraph-sdk<0.3.0,>=0.2.2->langgraph) (0.28.1)\n",
      "Requirement already satisfied: orjson>=3.10.1 in d:\\study\\gen ai\\langchain\\.venv\\lib\\site-packages (from langgraph-sdk<0.3.0,>=0.2.2->langgraph) (3.11.3)\n",
      "Requirement already satisfied: anyio in d:\\study\\gen ai\\langchain\\.venv\\lib\\site-packages (from httpx>=0.25.2->langgraph-sdk<0.3.0,>=0.2.2->langgraph) (4.10.0)\n",
      "Requirement already satisfied: certifi in d:\\study\\gen ai\\langchain\\.venv\\lib\\site-packages (from httpx>=0.25.2->langgraph-sdk<0.3.0,>=0.2.2->langgraph) (2025.8.3)\n",
      "Requirement already satisfied: httpcore==1.* in d:\\study\\gen ai\\langchain\\.venv\\lib\\site-packages (from httpx>=0.25.2->langgraph-sdk<0.3.0,>=0.2.2->langgraph) (1.0.9)\n",
      "Requirement already satisfied: idna in d:\\study\\gen ai\\langchain\\.venv\\lib\\site-packages (from httpx>=0.25.2->langgraph-sdk<0.3.0,>=0.2.2->langgraph) (3.10)\n",
      "Requirement already satisfied: h11>=0.16 in d:\\study\\gen ai\\langchain\\.venv\\lib\\site-packages (from httpcore==1.*->httpx>=0.25.2->langgraph-sdk<0.3.0,>=0.2.2->langgraph) (0.16.0)\n",
      "Requirement already satisfied: langsmith>=0.3.45 in d:\\study\\gen ai\\langchain\\.venv\\lib\\site-packages (from langchain-core>=0.1->langgraph) (0.4.21)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in d:\\study\\gen ai\\langchain\\.venv\\lib\\site-packages (from langchain-core>=0.1->langgraph) (9.1.2)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in d:\\study\\gen ai\\langchain\\.venv\\lib\\site-packages (from langchain-core>=0.1->langgraph) (1.33)\n",
      "Requirement already satisfied: PyYAML>=5.3 in d:\\study\\gen ai\\langchain\\.venv\\lib\\site-packages (from langchain-core>=0.1->langgraph) (6.0.2)\n",
      "Requirement already satisfied: typing-extensions>=4.7 in d:\\study\\gen ai\\langchain\\.venv\\lib\\site-packages (from langchain-core>=0.1->langgraph) (4.15.0)\n",
      "Requirement already satisfied: packaging>=23.2 in d:\\study\\gen ai\\langchain\\.venv\\lib\\site-packages (from langchain-core>=0.1->langgraph) (25.0)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in d:\\study\\gen ai\\langchain\\.venv\\lib\\site-packages (from jsonpatch<2.0,>=1.33->langchain-core>=0.1->langgraph) (3.0.0)\n",
      "Requirement already satisfied: requests-toolbelt>=1.0.0 in d:\\study\\gen ai\\langchain\\.venv\\lib\\site-packages (from langsmith>=0.3.45->langchain-core>=0.1->langgraph) (1.0.0)\n",
      "Requirement already satisfied: requests>=2.0.0 in d:\\study\\gen ai\\langchain\\.venv\\lib\\site-packages (from langsmith>=0.3.45->langchain-core>=0.1->langgraph) (2.32.5)\n",
      "Requirement already satisfied: zstandard>=0.23.0 in d:\\study\\gen ai\\langchain\\.venv\\lib\\site-packages (from langsmith>=0.3.45->langchain-core>=0.1->langgraph) (0.24.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in d:\\study\\gen ai\\langchain\\.venv\\lib\\site-packages (from pydantic>=2.7.4->langgraph) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.33.2 in d:\\study\\gen ai\\langchain\\.venv\\lib\\site-packages (from pydantic>=2.7.4->langgraph) (2.33.2)\n",
      "Requirement already satisfied: typing-inspection>=0.4.0 in d:\\study\\gen ai\\langchain\\.venv\\lib\\site-packages (from pydantic>=2.7.4->langgraph) (0.4.1)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in d:\\study\\gen ai\\langchain\\.venv\\lib\\site-packages (from requests>=2.0.0->langsmith>=0.3.45->langchain-core>=0.1->langgraph) (3.4.3)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in d:\\study\\gen ai\\langchain\\.venv\\lib\\site-packages (from requests>=2.0.0->langsmith>=0.3.45->langchain-core>=0.1->langgraph) (2.5.0)\n",
      "Requirement already satisfied: sniffio>=1.1 in d:\\study\\gen ai\\langchain\\.venv\\lib\\site-packages (from anyio->httpx>=0.25.2->langgraph-sdk<0.3.0,>=0.2.2->langgraph) (1.3.1)\n",
      "Downloading langgraph-0.6.6-py3-none-any.whl (153 kB)\n",
      "Downloading langgraph_checkpoint-2.1.1-py3-none-any.whl (43 kB)\n",
      "Downloading langgraph_prebuilt-0.6.4-py3-none-any.whl (28 kB)\n",
      "Downloading langgraph_sdk-0.2.4-py3-none-any.whl (53 kB)\n",
      "Downloading ormsgpack-1.10.0-cp313-cp313-win_amd64.whl (121 kB)\n",
      "Downloading xxhash-3.5.0-cp313-cp313-win_amd64.whl (30 kB)\n",
      "Installing collected packages: xxhash, ormsgpack, langgraph-sdk, langgraph-checkpoint, langgraph-prebuilt, langgraph\n",
      "\n",
      "   ------------- -------------------------- 2/6 [langgraph-sdk]\n",
      "   -------------------- ------------------- 3/6 [langgraph-checkpoint]\n",
      "   --------------------------------- ------ 5/6 [langgraph]\n",
      "   --------------------------------- ------ 5/6 [langgraph]\n",
      "   --------------------------------- ------ 5/6 [langgraph]\n",
      "   --------------------------------- ------ 5/6 [langgraph]\n",
      "   --------------------------------- ------ 5/6 [langgraph]\n",
      "   --------------------------------- ------ 5/6 [langgraph]\n",
      "   --------------------------------- ------ 5/6 [langgraph]\n",
      "   ---------------------------------------- 6/6 [langgraph]\n",
      "\n",
      "Successfully installed langgraph-0.6.6 langgraph-checkpoint-2.1.1 langgraph-prebuilt-0.6.4 langgraph-sdk-0.2.4 ormsgpack-1.10.0 xxhash-3.5.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install langgraph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ef82a5cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.utilities import SQLDatabase\n",
    "\n",
    "from langchain_ollama import OllamaLLM\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "os.environ[\"LANGCHAIN_TRACING_V2\"]=\"true\"\n",
    "os.environ[\"LANGCHAIN_API_KEY\"]=os.getenv(\"LANGCHAIN_API_KEY\")\n",
    "\n",
    "# -----------------------------\n",
    "# 1. Build connection string\n",
    "# -----------------------------\n",
    "# Replace YOUR_SERVER with your SQL Server Express instance name\n",
    "# Replace HRDatabase with your database name\n",
    "# Use trusted connection (Windows Auth) or add UID/PWD for SQL auth\n",
    "connection_string = (\n",
    "    \"mssql+pyodbc:///?odbc_connect=\"\n",
    "    \"Driver={ODBC Driver 17 for SQL Server};\"\n",
    "    \"Server=LAPTOP-E5BJ5PM9;\"\n",
    "    \"Database=HRDatabase;\"\n",
    "    \"Trusted_Connection=yes;\"\n",
    ")\n",
    "\n",
    "# -----------------------------\n",
    "# 2. Load SQLDatabase\n",
    "# -----------------------------\n",
    "db = SQLDatabase.from_uri(connection_string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "37f3b47d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Employees']\n"
     ]
    }
   ],
   "source": [
    "print(db.get_usable_table_names())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f6495c71",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"[(1, 'Alice Johnson', 'Python, React, AWS', 5, 'E-commerce Platform, Healthcare Dashboard', 'available'), (3, 'Alice Johnson', 'Python, React, AWS', 5, 'E-commerce Platform, Healthcare Dashboard', 'available'), (4, 'Bob Smith', 'Java, Spring Boot, MySQL', 7, 'Banking System, Loan Processing App', 'unavailable'), (5, 'Catherine Lee', 'C#, .NET, Azure', 4, 'Hospital Management, CRM Tool', 'available'), (6, 'David Kumar', 'Python, Django, PostgreSQL', 3, 'Inventory System, Chatbot', 'available'), (7, 'Emma Williams', 'JavaScript, Node.js, MongoDB', 6, 'Real-time Chat App, Food Delivery Platform', 'unavailable'), (8, 'Frank Miller', 'React Native, Firebase, Kotlin', 2, 'Mobile Wallet, Fitness Tracker', 'available'), (9, 'Grace Chen', 'Python, TensorFlow, SQL', 5, 'Healthcare AI Model, Fraud Detection', 'available'), (10, 'Henry Adams', 'PHP, Laravel, MySQL', 8, 'E-learning Platform, Blogging CMS', 'unavailable'), (11, 'Isabella Rossi', 'Ruby, Rails, PostgreSQL', 4, 'Event Booking System, Social Network', 'available'), (12, 'Jack Thompson', 'Go, Kubernetes, Docker', 6, 'Cloud Monitoring, Microservices Platform', 'available'), (13, 'Karen Patel', 'Java, AWS, Kafka', 3, 'Stock Trading App, Data Pipeline', 'unavailable'), (14, 'Liam Brown', 'Python, PyTorch, SQL', 2, 'Recommendation Engine, NLP Chatbot', 'available'), (15, 'Mia Davis', 'Angular, TypeScript, Node.js', 5, 'Project Management Tool, Online Exam Portal', 'unavailable'), (16, 'Noah Wilson', 'C++, Qt, OpenGL', 7, 'CAD Software, Simulation Tool', 'available'), (17, 'Olivia Martin', 'Swift, iOS SDK, CoreData', 4, 'Health Tracker App, E-commerce iOS App', 'available'), (18, 'Paul Green', 'Java, Spring, OracleDB', 9, 'ERP System, HR Management System', 'unavailable'), (19, 'Quinn Johnson', 'Python, Flask, SQLite', 1, 'Portfolio Website, Blogging App', 'available'), (20, 'Rajesh Gupta', 'Hadoop, Spark, Scala', 6, 'Big Data Analytics, ETL Pipeline', 'available'), (21, 'Sophia Turner', 'JavaScript, Vue.js, GraphQL', 3, 'Job Portal, Travel Booking Platform', 'unavailable'), (22, 'Thomas Clark', 'C, Embedded Systems, ARM', 10, 'IoT Devices, Automotive Software', 'available')]\""
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "db.run(\"SELECT * FROM Employees;\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "55dbc6d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing_extensions import TypedDict\n",
    "\n",
    "\n",
    "class State(TypedDict):\n",
    "    question: str\n",
    "    query: str\n",
    "    result: str\n",
    "    answer: str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "92a50104",
   "metadata": {},
   "outputs": [],
   "source": [
    "import getpass\n",
    "import os\n",
    "\n",
    "if not os.environ.get(\"GROQ_API_KEY\"):\n",
    "  os.environ[\"GROQ_API_KEY\"] = os.getenv(\"GROQ_API_KEY\")\n",
    "\n",
    "from langchain.chat_models import init_chat_model\n",
    "\n",
    "llm = init_chat_model(\"llama-3.3-70b-versatile\", model_provider=\"groq\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "8975d46c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================\u001b[1m System Message \u001b[0m================================\n",
      "\n",
      "\n",
      "Given an input question, create a syntactically correct \u001b[33;1m\u001b[1;3m{dialect}\u001b[0m query to\n",
      "run to help find the answer. Unless the user specifies in his question a\n",
      "specific number of examples they wish to obtain. You can order the results by a relevant column to\n",
      "return the most interesting examples in the database.\n",
      "\n",
      "Never query for all the columns from a specific table, only ask for a the\n",
      "few relevant columns given the question.\n",
      "\n",
      "Pay attention to use only the column names that you can see in the schema\n",
      "description. Be careful to not query for columns that do not exist. Also,\n",
      "pay attention to which column is in which table.\n",
      "\n",
      "Only use the following tables:\n",
      "\u001b[33;1m\u001b[1;3m{table_info}\u001b[0m\n",
      "\n",
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "Question: \u001b[33;1m\u001b[1;3m{input}\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "system_message = \"\"\"\n",
    "Given an input question, create a syntactically correct {dialect} query to\n",
    "run to help find the answer. Unless the user specifies in his question a\n",
    "specific number of examples they wish to obtain. You can order the results by a relevant column to\n",
    "return the most interesting examples in the database.\n",
    "\n",
    "Never query for all the columns from a specific table, only ask for a the\n",
    "few relevant columns given the question.\n",
    "\n",
    "Pay attention to use only the column names that you can see in the schema\n",
    "description. Be careful to not query for columns that do not exist. Also,\n",
    "pay attention to which column is in which table.\n",
    "\n",
    "Only use the following tables:\n",
    "{table_info}\n",
    "\"\"\"\n",
    "\n",
    "user_prompt = \"Question: {input}\"\n",
    "\n",
    "query_prompt_template = ChatPromptTemplate(\n",
    "    [(\"system\", system_message), (\"user\", user_prompt)]\n",
    ")\n",
    "\n",
    "for message in query_prompt_template.messages:\n",
    "    message.pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "4ce9f61d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing_extensions import Annotated\n",
    "from typing import TypedDict\n",
    "\n",
    "class QueryOutput(TypedDict):\n",
    "    \"\"\"Generated SQL query.\"\"\"\n",
    "\n",
    "    query: Annotated[str, ..., \"Syntactically valid SQL query.\"]\n",
    "\n",
    "\n",
    "def write_query(state: State):\n",
    "    \"\"\"Generate SQL query to fetch information.\"\"\"\n",
    "    prompt = query_prompt_template.invoke(\n",
    "        {\n",
    "            \"dialect\": db.dialect,\n",
    "            \"top_k\": 10,\n",
    "            \"table_info\": db.get_table_info(),\n",
    "            \"input\": state[\"question\"],\n",
    "        }\n",
    "    )\n",
    "    structured_llm = llm.with_structured_output(QueryOutput)\n",
    "    result = structured_llm.invoke(prompt)\n",
    "    return {\"query\": result[\"query\"]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "b46c122a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'query': 'SELECT COUNT(EmployeeID) FROM Employees'}"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "write_query({\"question\": \"How many Employees are there?\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "8b3ef641",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.tools.sql_database.tool import QuerySQLDatabaseTool\n",
    "\n",
    "\n",
    "def execute_query(state: State):\n",
    "    \"\"\"Execute SQL query.\"\"\"\n",
    "    execute_query_tool = QuerySQLDatabaseTool(db=db)\n",
    "    return {\"result\": execute_query_tool.invoke(state[\"query\"])}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "ad0b6a45",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'result': '[(21,)]'}"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "execute_query({\"query\": \"SELECT COUNT(EmployeeID) FROM Employees;\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "86c4974b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_answer(state: State):\n",
    "    \"\"\"Answer question using retrieved information as context.\"\"\"\n",
    "    prompt = (\n",
    "        \"Given the following user question, corresponding SQL query, \"\n",
    "        \"and SQL result, answer the user question.\\n\\n\"\n",
    "        f\"question: {state['question']}\\n\"\n",
    "        f\"SQL Query: {state['query']}\\n\"\n",
    "        f\"SQL Result: {state['result']}\"\n",
    "    )\n",
    "    response = llm.invoke(prompt)\n",
    "    return {\"answer\": response.content}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "8c6865d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.graph import START, StateGraph\n",
    "\n",
    "graph_builder = StateGraph(State).add_sequence(\n",
    "    [write_query, execute_query, generate_answer]\n",
    ")\n",
    "graph_builder.add_edge(START, \"write_query\")\n",
    "graph = graph_builder.compile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "65bdb133",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from IPython.display import Image, display\n",
    "\n",
    "# display(Image(graph.get_graph().draw_mermaid_png()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "65c46fa8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'write_query': {'query': \"SELECT COUNT(EmployeeID) FROM Employees WHERE Availability = 'unavailable'\"}}\n",
      "{'execute_query': {'result': '[(7,)]'}}\n",
      "{'generate_answer': {'answer': 'There are 7 employees who are unavailable.'}}\n"
     ]
    }
   ],
   "source": [
    "for step in graph.stream(\n",
    "    {\"question\": \"How many employees are unavailable?\"}, stream_mode=\"updates\"\n",
    "):\n",
    "    print(step)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "3501cc09",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'write_query': {'query': \"SELECT COUNT(EmployeeID) FROM Employees WHERE Skills LIKE '%Python%'\"}}\n",
      "{'execute_query': {'result': '[(6,)]'}}\n",
      "{'generate_answer': {'answer': 'There are 6 employees who have a skill in Python.'}}\n"
     ]
    }
   ],
   "source": [
    "for step in graph.stream(\n",
    "    {\"question\": \"How many employees have skill in Python?\"}, stream_mode=\"updates\"\n",
    "):\n",
    "    print(step)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "fdcb54a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'write_query': {'query': \"SELECT Name, ExperienceYears, Skills, Availability FROM Employees WHERE Projects LIKE '%Healthcare%' ORDER BY ExperienceYears DESC\"}}\n",
      "{'execute_query': {'result': \"[('Alice Johnson', 5, 'Python, React, AWS', 'available'), ('Alice Johnson', 5, 'Python, React, AWS', 'available'), ('Grace Chen', 5, 'Python, TensorFlow, SQL', 'available')]\"}}\n",
      "{'generate_answer': {'answer': 'Based on the SQL result, there are two employees with experience in healthcare projects: \\n\\n1. Alice Johnson - with 5 years of experience and skills in Python, React, and AWS. She is available.\\n2. Grace Chen - with 5 years of experience and skills in Python, TensorFlow, and SQL. She is available.\\n\\nNote that Alice Johnson appears twice in the result, possibly due to duplicate entries in the database. However, for the purpose of answering the user question, we can consider her as one candidate. \\n\\nBoth Alice Johnson and Grace Chen have the same amount of experience, so it ultimately depends on the specific skills required for the project. If the project requires skills in React and AWS, Alice Johnson might be a better fit. If the project requires skills in TensorFlow and SQL, Grace Chen might be more suitable.'}}\n"
     ]
    }
   ],
   "source": [
    "for step in graph.stream(\n",
    "    {\"question\": \"I need someone experienced in healthcare project?\"}, stream_mode=\"updates\"\n",
    "):\n",
    "    print(step)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0029b72",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
